\documentclass[a4paper,10pt]{report}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{url}
\usepackage{graphicx}
\usepackage{paralist}
\usepackage{listings,mdframed}
\usepackage[numbers]{natbib}
\usepackage[x11names]{xcolor}
% \usepackage{biblatex}
\selectlanguage{spanish}
\renewcommand{\lstlistingname}{Código}

% Title Page
\title{Aceleración de la visión por computadora utilizando GPUs, aplicación a fútbol de robots}
\author{Ignacio Eguinoa \\
\small Facultad de Informática, UNLP}
\date{}


\begin{document}
% \setdescription{leftmargin=0pt}
\maketitle


\begin{abstract}

% En este trabajo se desarrollan conceptos relacionados con la visión por computadora y la utilización de unidades de procesamiento gráfico(GPUs) para su optimización.


% En primer lugar se realiza una descripción general de la libreria OpenCV, detallando las opciones de aceleración que provee para algunas funcionalidades haciendo uso de arquitecturas paralelas. 

% En una segunda parte, se realiza un desarrollo experimental que consiste en modificar un algoritmo existente para el procesamiento de imágenes provenientes de fúbol de robots, el cual utiliza la librería OpenCV. 
% Se plantean variaciones para paralelizar distintos pasos de este procesamiento utlizando el modulo gpu de dicha libería. 
% Las distintas variantes son luego evaluadas utilizando un sistema de pruebas y los resultados se analizan en base a las caracterísicas de la arquitectura.

A lo largo del trabajo se recorren todos los aspectos relacionados con el uso de arquitecturas GPU para aplicaciones de visión por computadora. 

En primer lugar se muestran las propiedades de esta arquitectura usada para propósito general. 
Luego se explican en detalle como OpenCV permite acelerar algunas de sus funcionalidades usando esta arquitectura. La misma funcionalidad se muestra desde el punto de vista del usuario, al cual la librería le permite utilizar la arquitectura de forma transparente a la implementación subyacente.

Finalmente se ejemplifica el proceso de desarrollo para aplicaciones que utilizan este tipo de arquitecturas a través de OpenCV. 
El desarrollo que se muestra, independientemente de los resultados logrados, permite conocer como es el procedimiento que se debe seguir para evaluar cualquier posiblidad de acelerar cálculos sobre imágenes utilizando dispositivos GPU.

\end{abstract}


\tableofcontents























\chapter{Introduccion}

\section{Estructura del trabajo}
En lo que resta de este primer capítulo se realiza una introducción a la arquitectura GPU. 
El objetivo es dar una idea general de las caracterísicas que posee y las posiblidades que ofrece tanto para procesamiento de gráficos como para cómputo de propósito general.

% El capítulo 2 se centra en la libreria OpenCV, describiendo en forma general las funcionalidades que provee y, finalmente, detallando algunas variantes asociadas a la optimizacion por paralelismo que se utilizan en el desarrollo práctico al final del trabajo. 

El capítulo 2 se centra en la libreria OpenCV, donde se describe en primer lugar la estructura general y las funcionalidades que provee. 
Luego se describe el módulo específico que implementa funcionalidades aceleradas mediante procesadores gráficos.
En la última parte del capítulo se detallan las implementaciones de algunas funcionalidades caracterísicas del módulo, conectando los conceptos vistos de la arquitectura con la interfaz de la librería que el usuario utiliza de forma transparente. 

% funcionalidades que provee y, finalmente, detallando algunas variantes asociadas a la optimizacion por paralelismo que se utilizan en el desarrollo práctico al final del trabajo. 

El capítulo 3 muestra el desarrollo experimental asociado al trabajo. En primer lugar se describe el contexto de la aplicación y la implementacion existente para el procesamiento de imágenes de fútbol robot(libreria bottracker).
Luego se plantean modificaciones sobre el algoritmo, utilizando el módulo de GPU provisto por OpenCV. Se hacen evaluaciones de las distintas modificaciones y se analizan los resultados basandose en los conceptos explicados en los capitulos previos.













\section{La arquitectura GPU}

% ***********************************************************
% ********  GPU: LO DEJO PARA LO ULTIMO *********************
% ***********************************************************

% EN ESTA SECCION DEBERIA HABLAR DE CUDA Y TAMBIEN EXPLICAR OPENCL!!!!!!!!!!!!!!!!!!!!!!!1
% AGREGAR PRIMERO UNAS LINEAS MUY BREVES DE INTRODUCCION



% DESPUES PONGO ESTAS LINEAS
Modern GPU accelerators has become powerful and featured enough to be capable to perform general purpose computations (GPGPU).  
It is a very fast growing area that generates a lot of interest from scientists, researchers and engineers that develop computationally intensive applications. 
Despite of difficulties reimplementing algorithms on GPU, many people are doing it to check on how fast they could be. 
To support such efforts, a lot of advanced languages and tool have been available such as CUDA, OpenCL, C++ AMP, debuggers, profilers and so on.
% DESPUES DE ESTO APROVECHO PARA HABLAR BREVEMENTE DE OPENCL Y DECIR QUE ME ENFOCO EN CUDA Y bla bla...


% 
% ****************************************************************
% ****************************************************************
% COPIAR DE LA TESIS DE NITSCHE
% ****************************************************************
% ****************************************************************
% 












\chapter{La librería OpenCV}

\section{Generalidades}
OpenCV \footnote{Open Source Computer Vision Library \url{http://opencv.org}} es una librería open-source que se distribuye bajo licencia BSD. 
Reúne una gran cantidad de funcionalidades asociadas a la visión por computadoras, incluyendo estructuras para almacenamiento de datos y algoritmos de bajo y alto
nivel para el procesamiento de imágenes (desde transformaciones que se aplican directamente sobre las imágenes hasta reconocimiento de rostros y seguimiento de objetos).


La librería esta compuesta por distintos módulos que proveen funcionalidades independientes entre si. Entre los más conocidos están:

\begin{description}
 \item[Módulo core] \hfill \\Define funciones básicas utilizadas por los demás módulos y una estructura de datos central que se utiliza para almacenamiento de imágenes(detallada mas adelante)  
 \item[Módulo imgproc] \hfill \\Contiene algoritmos para aplicar a imagenes (filtros, transformaciones, conversiones de colores, etc)
 \item[Módulo video]\hfill \\ Incluye algoritmos que se aplican sobre elementos de video para estimar movimientos, seguimiento de objetos y para sustraer el fondo.
 \item[Módulo highgui]\hfill \\ Interface para captura de video. Además contiene funcionalidades para definir interfaces gráficas de usuario.
\end{description}


  
La librería esta implementada usando el lenguaje C++ y define un espacio de nombres(cv) bajo el cual se puede acceder tanto a las estructuras de datos como a las operaciones provistas por los distintos módulos.
En los siguientes recuadros se muestran algunos ejemplos de funcionalidades:


\begin{lstlisting}[caption={Módulo core},frame=bt,columns=fullflexible,numbers=left,backgroundcolor=\color{LemonChiffon1},basicstyle=\small,keywordstyle=\ttfamily\small,language=C++,stringstyle=\ttfamily,breaklines=true,xleftmargin=0.5em,xrightmargin=0pt,aboveskip=\bigskipamount,belowskip=\bigskipamount]
 #include "opencv2/core/core.hpp"
 cv::Mat img;				      //Estructura de datos para imagenes
 cv::absdiff(src1,src2,dst)  	          //Diferencia absoluta entre src1 y src2
 cv::transpose(src,dst)   	        //Calcula la transpuesta de la matriz src
 cv::dft(src,dst,flags, nonzeroRows)            //Discrete Fourier transformation
\end{lstlisting}



\begin{lstlisting}[caption={Módulo imgproc},frame=bt,columns=fullflexible,numbers=left,backgroundcolor=\color{LemonChiffon1},basicstyle=\small,keywordstyle=\ttfamily\small,language=C++,stringstyle=\ttfamily,breaklines=true,xleftmargin=0.5em,xrightmargin=0pt,aboveskip=\bigskipamount,belowskip=\bigskipamount]
 #include "opencv2/imgproc/imgproc.hpp" 
 cv::threshold(src,dst,thresh,maxval,type)   //aplica un umbral a los valores del input
 cv::Canny(InputArray image, OutputArray edges,.... ) //aplica el algoritmo de Canny para buscar bordes en la imagen
 cv::cvtColor(src,dst,code,...)   //convierte la imagen src de un espacio de colores a otro 
\end{lstlisting}

% 
% \begin{lstlisting}[caption={Módulo video},frame=bt,columns=fullflexible,numbers=left,backgroundcolor=\color{LemonChiffon1},basicstyle=\small,keywordstyle=\ttfamily\small,language=C++,stringstyle=\ttfamily,breaklines=true,xleftmargin=0.5em,xrightmargin=0pt,aboveskip=\bigskipamount,belowskip=\bigskipamount]
%  #include "opencv2/video/video.hpp"
%  
% \end{lstlisting}
% 



% ************************
% EXPLICO LA INTERFACE Mat
% ************************

El módulo core es probablemente el más importante, en parte por contener los algoritmos de más bajo nivel para manipular imágenes sobre los cuales se sustentan el resto de las operaciones pero, principalmente, porque 
contiene las definiciones para las estructuras de datos que provee la librería para almacenar las imágenes.

La principal función de la librería OpenCV es procesar imágenes las cuales, en cualquier sistema de cómputo, se encuentran almacenadas como matrices numéricas. 
El módulo core contiene una interface propia que es utilizada para el manejo de imágenes (entrada y salida) en todas las funciones de la librería. 
Presenta una forma simple y segura de manejar este tipo de información y es, por lo tanto, una de las partes centrales de OpenCV.

Inicialmente, OpenCV fue implementado usando el lenguaje C y se usaban estructuras de memoria propias del lenguaje para manejar las imágenes. 
El problema de esto es que todo el proceso de alocar y desalocar el espacio correspondiente se debe hacer de forma manual y queda en manos de quien está utilizando la librería. 
A partir de la version 2.0 de OpenCV, el código se extendió para usar el lenguaje C++ (aprovechando la compatibilidad entre ambos lenguajes) y en este proceso se introdujo una interface llamada Mat que apunta a automatizar todo el manejo de memoria. 
De esta forma, los programas que utilizaban la librería OpenCV se hacen más simples de desarrollar y manejar, incluso aquellos programas de gran tamaño.
Además, la mayoría de las funciones de OpenCV realizan la alocación de memoria necesaria para el resultado de forma automática y, si la entrada consiste en un objeto Mat ya instanciado, entonces el espacio de memoria de éste es reutilizado.

Mat es básicamente una clase con dos partes de datos: el encabezado de la matriz(contiene información tal como el tamaño, el método usado para almacenarla, la dirección de memoria, etc) y un puntero a la matriz conteniendo los valores de los pixeles (que puede tomar cualquier dimensión, dependiendo del método usado para almacenar).
El tamaño del encabezado es constante pero el tamaño de la matriz en si puede variar de imagen a imagen.

OpenCV utiliza un sistema para mantener el número de referencias por cada imagen, el cual permite que todo el proceso de copia y pasaje por parámetro involucre solo modificaciones en el encabezado (se debe especificar explícitamente si se quiere hacer una copia real de los datos de la matriz).
Además, permite liberar el espacio ocupado por una imagen una vez que ya no existen referencias a ésta.

Dadas estas propiedades, el manejo de imágenes es naturalmente transparente para el usuario, realizando además una manipulación eficiente de los datos.


% **********************
% FIN DE LA INTERFACE MAT
% **********************








% ESTA SECCION ES MEDIO APARTE, SE SUPONE QUE EN LA SECCION ANTERIOR YA HABLE DE LAS FUNCIONALIDADES GENERALES QUE PROVEE OPENCV
% ACA DEBERIA HABLAR PURAMENTE DE PARALELISMO APLICADO A COMPUTER VISION
\section{Paralelismo y cómputo heterogéneo}


% PRIMERO PONGO UN PAR DE LINEAS DE INTRODUCCION MUUUUUY GENERALES SOBRE PARALELISMO 

Históricamente, la forma mas simple de aumentar la performance en la ejecución de un algoritmo era esperar a que avance el proceso natural de mejora en los transistores(Ley de Moore).
Al cabo de un tiempo, esto resultaba en un aumento de la velocidad del reloj en los dispositivos. Cuando este aumento ocurria, las aplicaciones se acelearaban automaticamente sin necesidad de modificar el código.
A medida que aumentaba la densidad de transistores también aumento la perdida de energia en forma de calor y esto puso un límite en el número de transistores que pueden integrarse eficientemente.
La eficiencia energetica puso un limite en la potencia individual de los transistores de forma que un aumento en la densidad de estos no se traduce en una mejora directa
de la performace en la CPU. 

El proceso de mejora continuó permitiendo cada vez mas transistores por unidad de superficie, existiendo dos formas comúnes de traducir esta mejora en una *****Implementacion****  aprovechable

En primer lugar esta la paralelización, que consiste en crear mas unidades idénticas en lugar de intentar hacer unidades mas rápidas y potentes.

La otra forma de aprovecharlo es mediante especialización, es decir, construir hardware específico para realizar una cierta clase de funciones de forma más eficiente.

Ciertos campos de aplicacion, que desarrollan continuamente aplicaciones con requerimientos intensivos de computo, tienen la necesidad de obtener constantemente mayores capacidades por parte del hardware lo que lleva a combinar estas dos ideas,es decir, utilizar conjuntamente múltiples unidades de procesamiento(CPUs) a la par de dispositivos específicos de aceleración, 
concepto denominado cómputo paralelo heterogéneo.

Sin embargo, la evolución que existió hasta hace algún tiempo donde las aplicaciones mejoraban su rendimiento a la par del hardware sin necesidad de modificar las implementaciones ya no es algo posible y, hoy en día, es necesario
adaptar los algoritmos a los nuevos modelos de cómputo y el hardware heterogéneo.

% *************************PONELE QUE HASTA ACA ESTA BASTAAAANTE BIEN***************


La visión por computadoras, y el procesamiento de imágenes en general, es una de las áreas que requiere constantemente mayores capacidades de computo por parte del hardware. 
Además, muchos de los algoritmos pertenecientes a este campo se caracterízan por ser  ****embarrassingly parallel****........ ....
por lo tanto son ****candidatos usuales para hacer uso**** del computo paralelo heterogeneo, haciendo uso de dispositivos con las arquitecturas altamente paralelas como las GPUs.
% The GPU (graphics processing unit), for example, is an accelerator that is now available on every desktop computer, as well as on mobile devices such as smart phones and tablets.

Como se explicó en el capitulo 1, la funcion inicial de la gpu era renderizar imagenes a partir de escenas y, con el tiempo, la gran versatilidad de estos dispositivos llevo a que se implementen funciones completamente distintas que mapeaban correctamente con la arquitectura. 
% Por ej. mediante el modulo de gpu de la libreria OpenCV se estan realizando la funcion opuesta, que es entender las escenas a partir de imagenes. ((ver filmina 11 de la presentacion ))
En la introducción de esta sección se mencionó que los algoritmos asociados a la visión por computadora eran tareas que generalmente mapeaban de forma natural con dispositivos GPU. 
Esto, sin embargo, no es una conoincidencia, ya que la vision por computadora resuelve el problema inverso al cual se apuntaba especificamente al diseñar las GPUs.
De esta forma, mientras el pipeline gráfico original transforma la descripción de una escena en pixeles, la visión por computadora transforma los pixeles en información útil de alto nivel.
% Computer vision is one of the tasks that often naturally map to GPUs. This is not a coincidence, as computer vision solves the inverse of the computer graphics problem.
% While graphics transforms a scene or object description to pixels, vision transforms pixels to higher-level information.


En el caso de OpenCV, las caracteristicas intrinsecamente paralelas de algunos de sus algoritmos son explotadas utilizando dos plataformas muy conocidas para paralelismo y computo heterogeneo:
% High-level computer-vision tasks often contain subtasks that can be run faster on special-purpose hardware architectures than on the CPU, while other subtasks are computed on the CPU.
% La librería OpenCV tiene soporte para acelerar algunas funcionalidades de procesamiento haciendo uso de este tipo de arquitecturas heterogeneas. 
% Para lograr esto utiliza dos plataformas muy conocidas:
-Por un lado utiliza el framework OpenCL, el cual permite escribir programas destinados a ser ejecutados sobre plataformas que contienen unidades de CPUs y otro tipo de procesadores, 
generalmente utilizados como aceleradores de calculo, tales como  graphics processing units (GPUs), digital signal processors (DSPs) y field-programmable gate arrays (FPGAs).
-Otras implementaciones utilizan la plataforma CUDA, un modelo de programacion creado por NVIDIA y solo implementado en las GPUs de su linea. Si bien parece un tanto restrictivo, 
esta plataforma tuvo un gran exito y ha dominado el area de programacion heterogenea en los ultimos años.



% GPUs contain lots of similar processing units and are very efficient in executing simple, similar subtasks such as rendering or filtering pixels. 
% Such tasks are often known as “embarrassingly parallel,” because they are so easy to parallelize efficiently on a GPU.

Ademas de este conjunto de funciones altamente paralelizables, muchas otras tareas asociadas al campo de la vision por computadora sin dificiles de adaptar
a estas arquitecturas debido a que contienen segmentos secuenciales dependientes entre si.
% Many tasks, however, do not parallelize easily, as they contain serial segments where the results of the later stages depend on the results of earlier stages.
Estos algoritmos, por lo tanto, no se adaptan correctamente a las GPUs, no hacen un uso eficiente de esta y suelen ser mas fáciles de implementar(incluso obteniendo mejor performance) sobre CPUs.

% These serial algorithms do not run efficiently on GPUs and are much easier to program and often run faster on CPUs. 
% Many iterative numerical optimization algorithms and stack-based tree-search algorithms belong to that class.

Muchos algoritmos de alto nivel están compuestos de diversas subtareas, algunas de las cuales son facilmente paralelizables (y por lo tanto pueden ser aceleradas mediante GPUs), 
y otras tienen caracteristicas naturalmente secuenciales(y por lo tanto corren mas eficientemente sobre CPUs)
La combinacion de componentes que corren sobre CPU y componentes que corren sobre GPU en una misma tarea global tiene al menos dos fuentes importantes de ineficiencia:
% Since many high-level tasks consist of both parallel and serial subtasks, the entire task can be accelerated by running some of its components on the CPU and others on the GPU. 
% Unfortunately, this introduces two sources of inefficiency. 
Una de ellas es la sincronización: cuando una subtarea depende de los resultados de otra, ésta última debe esperar a que la otra termine para comenzar.
% One is synchronization: when one subtask depends on the results of another, the later stage needs to wait until the previous stage is done. 
La segunda fuente de ineficiencia corresponde al overhead asociado a la transferencia de datos ente las memoria de la CPU y la GPU. Este problema es particularmente importante en los algoritmos de visión por computadora ya que
operan principalmente sobre imagenes, lo cual involucra mover grandes cantidades de datos.
% The other inefficiency is the overhead of moving the data back and forth between the GPU and CPU memories—and since computer-vision tasks need to process lots of pixels, it can mean moving massive data chunks back and forth. 
Estos aspectos deben ser tenidos en cuenta cuando se intenta acelerar una aplicacion mediante programacion heterogenea, ejecutando tareas sobre CPU y GPU en un mismo procedimiento.
% These are the key challenges in accelerating computer-vision tasks on a system with both a CPU and GPU.



% *********************************************
% ********************************************











\subsection{El modulo gpu}




% 
% 
% A continuación se va a detallar el modulo gpu de OpenCV, el cual se implementa sobre la plataforma CUDA exclusivamente. 
% Además, el resto del trabajo esta enfocado en detallar y utilizar este módulo, aunque se harán referencias a ciertas implementaciones que utilizan OpenCL cuando se crea conveniente resaltarlo.
% 
% 
% 


% AL FINAL DE LA EXPLICACION GENERAL ARRANCO CON LA EXPLICACION DEL MODULO GPU
% EXPLICAR QUE EL MODULO GPU ESTA ORIENTADO A CUDA!!!!!!!!!!!  QUE HAY IMPLEMENTACIONES DE ALGUNOS ALGORITMOS PARA OPENCL PERO ESTAN APARTE!!!!!

Como se mencionó en la sección anterior, CUDA es la principal plataforma para programacion heterogenea, fundamentalmente por el dominio de NVIDIA en el mercado de GPUs.
Es por esto que a fines de 2010, cuando se comenzo a implementar el módulo gpu de OpenCV, se utilizó esta plataforma para desarrollarlo. Junto con la gran popularidad de los dispositivos NVIDIA, 
la plataforma CUDA contiene una importante comunidad de usuarios, conferencias específicas, plublicaciones asociadas, y muchas herramientas y librerías desarrolladas específicamente, lo cual facilita en gran parte el avance en proyectos open-source tales como OpenCV.

En 2011 fue lanzada la primer versión del módulo, el cual contiene todas las funcionalidades aceleradas mediante GPU (reimplementaciones de algoritmos que ya se encuentraban entre los otros módulos) 

Este nuevo módulo es totalmente consistente con la versión en CPU, es decir, la forma de llamar a las funciones implementadas para la nueva arquitectura es equivalente a la forma en que se utilizaban las funciones desarrolladas para CPU.
Esto hace que sea muy facil de adaptar el código para utilizarlo.
% The module is consistent with the CPU version of OpenCV, which makes adoption easy. 


Ya se ha resaltado la importancia que tiene el manejo de datos cuando se utilizan dispositivos tipo GPU para la aceleración del cómputo, por lo tanto, al desarrollar una extensión de la librería que contenga este tipo de implementaciones es necesario tener muy en cuenta como se hace el manejo de datos.



Por su parte, el modulo gpu define la siguiente clase:

class gpu::GpuMat
Base storage class for GPU memory with reference counting. Its interface matches the Mat interface with the following limitations:
no arbitrary dimensions support (only 2D)
no functions that return references to their data (because references on GPU are not valid for CPU)
no expression templates technique support

All GPU functions receive GpuMat as input and output arguments. This allows to invoke several GPU algorithms without downloading data. GPU module API interface is also kept similar with CPU interface where possible. So developers who are familiar with Opencv on CPU could start using GPU straightaway.


In the GPU module the container cv::gpu::GpuMat stores the image data in the GPU memory and does not provide direct access to the data. If users want to modify the pixel data in the main program running on the GPU, they first need to copy the data from GpuMat to Mat.


De esta forma, el módulo GPU esta diseñado como una extension de la vista del host que tiene la API. Este diseño permite que el usuario controle explícitamente la transferencia de datos entre la memoria de CPU y GPU.
% The GPU module is designed as host API extension. This design provides the user an explicit control on how data is moved between CPU and GPU memory. 
Si bien esto implica tener que explicitar una pequeña porción de código adicional para ejecutar el código sobre la GPU (no se logra simplemente llamando a funciones del módulo gpu, también se deben transferir los datos), resulta en un forma flexible y eficiente de ejecutar las operaciones. 

% Although the user has to write some additional code to start using the GPU, this approach is both flexible and allows more efficient computations.

A continuación se muestra un ejemplo sencillo de portación de un código que corre exclusivamente en CPU a uno que utiliza funcionalidades del módulo GPU.

\begin{lstlisting}[frame=bt,title={aa},caption={Aplicar threshold a imagen en gris - CPU},
columns=fullflexible,numbers=left,backgroundcolor=\color{LemonChiffon1},basicstyle=\footnotesize,keywordstyle=\ttfamily\footnotesize,language=C++,stringstyle=\ttfamily,breaklines=true,xleftmargin=0.5em,xrightmargin=0pt,aboveskip=\bigskipamount,belowskip=\bigskipamount]
#include <iostream>
#include "opencv2/opencv.hpp"

int main (int argc, char* argv[])
{
    try
    {
        cv::Mat dst;
        cv::Mat src = cv::imread("file.png", CV_LOAD_IMAGE_GRAYSCALE);
        cv::threshold(src, dst, 128.0, 255.0, CV_THRESH_BINARY);
        cv::imshow("Result", dst);
        cv::waitKey();
    }
    catch(const cv::Exception& ex)
    {
        std::cout << "Error: " << ex.what() << std::endl;
    }
    return 0;
}

\end{lstlisting}

En las líneas 8 y 9 se declaran dos instancias de la interface Mat, dst y src, y se inicializa esta última con una imagen almacenada y leida en escala de gris.

En la linea 10 se aplica la función threshold  (la misma operación se encarga de alocar el espacio necesario para la imagen resultante en la variable dst, la cual no habia sido instanciada.
El resultado queda almacenado en la memoria del host, asociado a la variable dst, y puede mostrarse en la linea 11 usando la funcion imshow(esta función, correspondiente al módulo highui muestra una imagen dentro de una ventana).

A continuación se muestra como varía el mismo código para poder ejecutar la aplicación del threshold sobre una GPU.

\begin{lstlisting}[frame=bt,title={aa},caption={Aplicar threshold a imagen en gris - GPU},
columns=fullflexible,numbers=left,backgroundcolor=\color{LemonChiffon1},basicstyle=\footnotesize,keywordstyle=\ttfamily\footnotesize,language=C++,stringstyle=\ttfamily,breaklines=true,xleftmargin=0.5em,xrightmargin=0pt,aboveskip=\bigskipamount,belowskip=\bigskipamount]
#include <iostream>
#include "opencv2/opencv.hpp"
#include "opencv2/gpu/gpu.hpp"

int main (int argc, char* argv[])
{
    try
    {
        cv::Mat src_host = cv::imread("file.png", CV_LOAD_IMAGE_GRAYSCALE);
        cv::gpu::GpuMat dst, src;
        src.upload(src_host);
        cv::gpu::threshold(src, dst, 128.0, 255.0, CV_THRESH_BINARY);
        cv::Mat result_host = dst;
        cv::imshow("Result", result_host);
        cv::waitKey();
    }
    catch(const cv::Exception& ex)
    {
        std::cout << "Error: " << ex.what() << std::endl;
    }
    return 0;
}

\end{lstlisting}

En la línea 9 se instancia una variable conteniendo la imagen en la memoria del host. Para poder aplicar la funcion threshold utilizando la GPU primero se deben transferir los datos para que sean accesibles por ésta.
En la línea 10 se declaran las variables que contendran los datos de entrada y salida en la GPU (src y dst respectivamente).
En la línea 11 se indica explícitamente la transferencia de los datos desde la memoria del host a la memoria global de la GPU (funcion upload). 
Luego de aplicar la operación sobre la GPU(línea 12) es necesario descargar el resultado si se quiere ,por ej., mostrarlo por pantalla. 
Para esto existen diferentes formas, en la línea 13 del código anterior se ve que se hace simplemente la asignación del contenido de la variable en GPU a una nueva variable sobre la memoria del host(esto resulta muy transparente para el usuario pero implica un alto costo de transferencia en el caso de imagenes de tamaño considerable).
Otra forma de hacerlo es mediante la funcion download, la cual puede usarse de forma sincrónica o asincrónica.

Como se ve en este ejemplo, las llamadas a ejecutar la función son equivalentes en CPU y GPU (solo cambia el espacio de nombres cv por cv::gpu). 
Sin embargo, se debe modificar el contexto de la llamada para asegurarse que los datos estén en el lugar correcto para ejecutar cada operación.









\subsection{Transformacion de imágenes}

% ACA PONGO DE FORMA GENERAL COMO IMPLEMENTA OPENCV LA APLICACION DE UNA OPERACION SOBRE UNA IMAGEN (O DOS) PARA TRANSFORMALA DE UN ESPACIO A OTRO

Una de las funcionalidades mas simples para acelerar mediante el uso de paralelismo es la de aplicar una función sobre cada uno de los pixeles de una imagen, generando una nueva imagen con el resultado de esta función
La forma secuencial de resolver esto sería recorrer todos los valores de la matriz, utilizando dos for anidados. 
Sin embargo, si la aplicación de la funcion es independiente entre los pixeles es muy simple pensar que los cálculos se pueden realizar totalmente en paralelo.

Usando los conceptos de CUDA y la arquitectura GPU introducidos en el capitulo 1, OpenCV implementa esta funcionalidad de la siguiente forma:


%  esta en https://github.com/Itseez/opencv/blob/2.4.10.x-prep/modules/gpu/include/opencv2/gpu/device/detail/transform_detail.hpp
% opencv2/gpu/device/detail/transform_detail.hpp

\begin{lstlisting}[frame=bt,caption={gpu/include/opencv2/gpu/device/detail/transform\_detail.hpp},
columns=fullflexible,numbers=left,backgroundcolor=\color{LemonChiffon1},basicstyle=\footnotesize,keywordstyle=\ttfamily\footnotesize,language=C++,stringstyle=\ttfamily,breaklines=true,xleftmargin=0.5em,xrightmargin=0pt,aboveskip=\bigskipamount,belowskip=\bigskipamount]
template <typename T, typename D, typename UnOp, typename Mask>
__global__ static void transformSimple(const PtrStepSz<T> src, PtrStep<D> dst, const Mask mask, const UnOp op)
  {
    const int x = blockDim.x * blockIdx.x + threadIdx.x;
    const int y = blockDim.y * blockIdx.y + threadIdx.y;

    if (x < src.cols && y < src.rows && mask(y, x))
      {
	dst.ptr(y)[x] = op(src.ptr(y)[x]);
      }
  }

\end{lstlisting}

En el código anterior se muestra el template utilizado para el kernel:

Los parámetros src y dst se corresponden con la imagen original y el resultado luego de la transformación.
La operacion aplicada sobre cada pixel(op, linea 9) depende en cada caso de la funcion que se quiera aplicar sobre el input.

El kernel es llamado de tal forma que se genera un thread por cada pixel de la imagen.
En las lineas 4 y 5 se definen valores de x e y para mapear cada thread con un par (x,y).
Los threads que caen en valores de x mayores que el ancho de la imagen o en valores de y mayores que el largo no tendran ningun pixel sobre el cual trabajar, entonces el thread hace un return instantáneamente.



% ************************************************************
% *************EN LA VERSION 3.0 ****************************
% **************************************************************

% EN LA VERSION 3.0, LA MISMA FUNCION SE ENCUENTRA IMPLEMENTADA EN :  /modules/cudev/include/opencv2/cudev/grid/detail/transform.hpp
%    https://github.com/Itseez/opencv/blob/da1ac359304df7e3a933e83babc5be5f49bc48a9/modules/cudev/include/opencv2/cudev/grid/detail/transform.hpp
%  pegar el kernel que esta entre las lineas 158 y 168

% \begin{lstlisting}[frame=bt,title={aa},caption={modules/cudev/include/opencv2/cudev/grid/detail/transform.hpp},
% columns=fullflexible,numbers=left,backgroundcolor=\color{LemonChiffon1},basicstyle=\footnotesize,keywordstyle=\ttfamily\footnotesize,language=C++,stringstyle=\ttfamily,breaklines=true,xleftmargin=0.5em,xrightmargin=0pt,aboveskip=\bigskipamount,belowskip=\bigskipamount]
% template <class SrcPtr, typename DstType, class UnOp, class MaskPtr> 
% __global__ void transformSimple(const SrcPtr src, GlobPtr<DstType> dst, const UnOp op, const MaskPtr mask, const int rows, const int cols) 
%   {
%     const int x = blockIdx.x * blockDim.x + threadIdx.x;
%     const int y = blockIdx.y * blockDim.y + threadIdx.y;
% 
%     if (x >= cols || y >= rows || !mask(y, x))
%       return;
% 
%     dst(y, x) = saturate_cast<DstType>(op(src(y, x)));
%   }
% \end{lstlisting}
% 












A continuación se muestra el template utilizado para generar los threads llamando al kernel anterior.
% pongo como se llama al kernel?? division en bloques y grid???
% esta en el mismo file: https://github.com/Itseez/opencv/blob/da1ac359304df7e3a933e83babc5be5f49bc48a9/modules/cudev/include/opencv2/cudev/grid/detail/transform.hpp



\begin{lstlisting}[frame=bt,title={aa},caption={gpu/include/opencv2/gpu/device/detail/transform\_detail.hpp},
columns=fullflexible,numbers=left,backgroundcolor=\color{LemonChiffon1},basicstyle=\footnotesize,keywordstyle=\ttfamily\footnotesize,language=C++,stringstyle=\ttfamily,breaklines=true,xleftmargin=0.5em,xrightmargin=0pt,aboveskip=\bigskipamount,belowskip=\bigskipamount]

template <typename T, typename D, typename UnOp, typename Mask>
static void call(PtrStepSz<T> src, PtrStepSz<D> dst, UnOp op, Mask mask, cudaStream_t stream)
  {
    typedef TransformFunctorTraits<UnOp> ft;

    const dim3 threads(ft::simple_block_dim_x, ft::simple_block_dim_y, 1);
    const dim3 grid(divUp(src.cols, threads.x), divUp(src.rows, threads.y), 1);

    transformSimple<T, D><<<grid, threads, 0, stream>>>(src, dst, mask, op);
    cudaSafeCall( cudaGetLastError() );

    if (stream == 0)
	cudaSafeCall( cudaDeviceSynchronize() );
  }
\end{lstlisting}







% EN LA VERSION 3.0 HAY UNA PEQUEÑA DIFERENCIA

% 
% \begin{lstlisting}[frame=bt,title={aa},caption={modules/cudev/include/opencv2/cudev/grid/detail/transform.hpp},
% columns=fullflexible,numbers=left,backgroundcolor=\color{LemonChiffon1},basicstyle=\footnotesize,keywordstyle=\ttfamily\footnotesize,language=C++,stringstyle=\ttfamily,breaklines=true,xleftmargin=0.5em,xrightmargin=0pt,aboveskip=\bigskipamount,belowskip=\bigskipamount]
% template <class SrcPtr1, class SrcPtr2, typename DstType, class BinOp, class MaskPtr> 
% __host__ static void call(const SrcPtr1& src1, const SrcPtr2& src2, const GlobPtr<DstType>& dst, const BinOp& op, const MaskPtr& mask, int rows, int cols, cudaStream_t stream)
%   {
%     const dim3 block(Policy::block_size_x, Policy::block_size_y);
%     const dim3 grid(divUp(cols, block.x), divUp(rows, block.y));
% 
%     transformSimple<<<grid, block, 0, stream>>>(src1, src2, dst, op, mask, rows, cols);
%     CV_CUDEV_SAFE_CALL( cudaGetLastError() );
% 
%     if (stream == 0)
%       CV_CUDEV_SAFE_CALL( cudaDeviceSynchronize() );
%   }
% \end{lstlisting}


En las lineas 7 y 8 se definen las variables que indican el tamaño del bloque y el grid para ejecutar el kernel sobre la gpu, los cuales tienen tamaños estandar definidos por la librería.

En la linea 10 se ve la llamada al kernel que realiza la transformación.








A modo de comparación se muestra cómo el mismo codigo es implementado usando el framework OpenCL:
% BUSCAR DONDE ESTA EL .cl DE LA VERSION 2.4 
%  https://github.com/Itseez/opencv/blob/master/modules/imgproc/src/opencl/cvtcolor.cl         desde la linea 133, 

\begin{lstlisting}[frame=bt,title={aa},caption={imgproc/src/opencl/cvtcolor.cl},
columns=fullflexible,numbers=left,backgroundcolor=\color{LemonChiffon1},basicstyle=\footnotesize,keywordstyle=\ttfamily\footnotesize,language=C++,stringstyle=\ttfamily,breaklines=true,xleftmargin=0.5em,xrightmargin=0pt,aboveskip=\bigskipamount,belowskip=\bigskipamount]

__kernel void RGB2Gray(__global const uchar * srcptr, int src_step, int src_offset, __global uchar * dstptr, int dst_step, int dst_offset, int rows, int cols)
{
  int x = get_global_id(0);
  int y = get_global_id(1) * PIX_PER_WI_Y;

  if (x < cols)
  {
      int src_index = mad24(y, src_step, mad24(x, scnbytes, src_offset));
      int dst_index = mad24(y, dst_step, mad24(x, dcnbytes, dst_offset));

      #pragma unroll
      for (int cy = 0; cy < PIX_PER_WI_Y; ++cy)
      {
	  if (y < rows)
	  {
	    __global const DATA_TYPE* src = (__global const DATA_TYPE*)(srcptr + src_index);
	    __global DATA_TYPE* dst = (__global DATA_TYPE*)(dstptr + dst_index);
	    DATA_TYPE_4 src_pix = vload4(0, src);
#ifdef DEPTH_5
	    dst[0] = fma(src_pix.B_COMP, 0.114f, fma(src_pix.G_COMP, 0.587f, src_pix.R_COMP * 0.299f));
#else
	    dst[0] = (DATA_TYPE)CV_DESCALE(mad24(src_pix.B_COMP, B2Y, mad24(src_pix.G_COMP, G2Y, mul24(src_pix.R_COMP, R2Y))), yuv_shift);
#endif
	    ++y;
	    src_index += src_step;
	    dst_index += dst_step;
          }
      }
  }
}
\end{lstlisting}


No se va a hacer una descripción detallada del código pero, de forma general, el código se llama 1 vez por cada columna de la matriz y, dentro de esta función, el segundo for esta paralelizado usando la directiva \#pragma unroll (linea 145,primitiva para paralelizar las iteraciones) aplicada a un for que itera sobre el numero de filas .







% AHORA EXPLICO CUAL ES LA DIFERENCIA SI QUIERO UTILIZAR UNA OPERACION QUE TOMA COMO INPUT 2 IMAGENES
En el ejemplo anterior la función de transformación era aplicada sobre un solo dato de entrada. 
El mismo esquema de paralelizacóon se puede utilizar para operaciones que tiene como entrada pixeles correspondientes a distintas imagenes. 
El proceso es muy similar al caso anterior (transformación unaria), pero ahora se trabaja con dos imágenes que se reciben por parámetro. 
% La libreria utiliza un template muy similar al anterior pero cuyo objetivo es generalizar la aplicacion de transformaciones binarias (es decir, que generan una salida a partir de 2 imagenes de entrada).

El template utilizado ahora para el kernel es:
 
\begin{lstlisting}[frame=bt,title={aa},caption={modules/cudev/include/opencv2/cudev/grid/detail/transform.hpp},
columns=fullflexible,numbers=left,backgroundcolor=\color{LemonChiffon1},basicstyle=\footnotesize,keywordstyle=\ttfamily\footnotesize,language=C++,stringstyle=\ttfamily,breaklines=true,xleftmargin=0.5em,xrightmargin=0pt,aboveskip=\bigskipamount,belowskip=\bigskipamount]
template <class SrcPtr1, class SrcPtr2, typename DstType, class BinOp, class MaskPtr>
__global__ void transformSimple(const SrcPtr1 src1, const SrcPtr2 src2, GlobPtr<DstType> dst, const BinOp op, const MaskPtr mask, const int rows, const int cols)
  {
    const int x = blockIdx.x * blockDim.x + threadIdx.x;
    const int y = blockIdx.y * blockDim.y + threadIdx.y;

    if (x >= cols || y >= rows || !mask(y, x))
      return;

    dst(y, x) = saturate_cast<DstType>(op(src1(y, x), src2(y, x)));
  }
\end{lstlisting}



Como se ve en la línea 10, ahora la funcion (op) recibe por parámetro dos elementos de imágenes distintas.





Las funciones de transformación mostradas en esta sección son solo algunas de las funcionalidades que estan implementadas en el módulo GPU en OpenCV. 
Se tomaron como ejemplo en primer lugar por su simplicidad a la hora de ser paralelizadas pero además porque estas funciones abstractas de transformación generalizan la implementación
de distintas operaciones que se utilizarán para el desarrollo experimental en la segunda parte de este trabajo.
















\chapter{Trabajo experimental}
\section{Futbol robot}
% Aca explico el problema en si
El trabajo consiste en un sistema de visión por computador para el reconocimiento de objetos en un partido de Futbol de robots.
El futbol de robots se puede definir como una competición de tecnología robótica de avanzada en un espacio contenido
Este trabajo se acota a una categoría particular de la competencia, en la cual los equipos se componen de 5 robots controlados por un sistema centralizado. 
Los robots se identifican por el color de sus 'camisetas'. Cada robot debe llevar el color designado para su equipo y puede llevar otros colores para identificar los robots dentro de un equipo.
No puede tener el color del equipo contrario en ningun lugar de su camiseta.
Ademas, ningun robot puede tener el color caracterísico de la pelota(naranja) en su camiseta.
Todo el procesamiento se realiza desde un sistema central y no se permite la intervencion de humanos a menos que el juego este detenido.
El sistema central dispone de las imágenes tomadas por una unica camara central situada sobre el campo de juego.
Una forma de definir el sistema de control es dividir el problema en las siguientes áreas:
Reconocimiento del campo: usando la imagen de la cámara, y posiblemente información anterior, se determina la posición, velocidad y orientación de los robots de ambos equipos y de la pelota.
Planificación de las acciones de los robots: Se determina las acciones a tomar con objeto de lograr el objetivo de trasladar la pelota al objetivo.
Control de los robots: Se usa un sistema de comunicación inalámbrico para mover los robots de acuerdo a la estrategia definida.


\section{Detección en tiempo real}
Dentro de las etapas definidas en la seccion anterior hay diversos procesos que requieren de tiempo: latencia de la camara(desde que se toma la imagen hasta que se comienza a procesar),
latencia de la deteccion, latencia de definicion de estrategia, latencia de comunicación.
El objetivo es que la toma de decisiones y la ejecucion de estas se realice en un tiempo donde la imagen sobre la cual se estan tomando las decisiones sea representativa del estado actual del campo.
La realidad es que el sistema está en continuo cambio, aún cuando los tiempos de latencia sean muy chicos, por lo tanto se realizan 2 aproximaciones: 
-Modificar los algoritmos de toma de decisiones para tener en cuenta que el sistema ha cambiado desde que se tiene la informacion, posiblemente usando informacion anterior.
-disminuir lo mas posible la latencia en todos los pasos del procesamiento, de forma tal que la imagen sea lo mas actual posible.

En un sistema de tiempo real duro, el procesamiento solo sería válido si se completan todas las etapas antes de que se capture la proxima imágen, la cual invalida el estado descrito por la imagen anterior.

\section{Implementacion existente}

El trabajo esta centrado en el primer paso del procesamiento central para futbol robot, esto es, la etapa de reconocimiento del campo. 
En este paso, se recibe una imagen actual del estado del campo y a partir de esta se deben detectar las posiciones de los robots de cada equipo y de la pelota.
% Dado que esta información sera utilizada para planificar las acciones a realizar por los robots, es necesario disminuir la latencia en el proceso de detección de los elementos del campo(robots, pelotas, etc)
% Como no se trabaja con un sistema operativo de tiempo real duro que impone limites en los tiempos de procesamiento, se realizan las mediciones que indican cual es la latencia en esta etapa.


Para realizar esto disponemos de una libreria \cite{Jaureguiberry} que permite realizar el procesamiento de estos frames. 
La funcion central de la libreria recibe por parametro una imagen correspondiente al cuadro actual del estado del campo y detecta a partir de este los elementos de interes 
(robots y pelota) devolviendo la información relevante. 

El proceso de detección no se va a explicar nuevamente pero se puede encontrar en detalle en Ref. \cite[capitulo 5]{Jaureguiberry}
En esta sección se veran en forma general los pasos del procesamiento y se detallaran las funcionalidades optimizadas usando gpu.




\subsection{La libreria bottracker}

La clase central de la libreria es bot\_tracker \cite[]{Jaureguiberry}. 
Esta clase necesita ser instanciada y configurada con los parametros necesarios(imagen de background, colores, etc) para poder realizar todo el proceso de detección.

% Explicar de forma simple los pasos




% SECCION APARTE EMPIEZO A HABLAR DE QUE COSAS Y COMO VOY A OPTIMIZAR USANDO GPUs
\section{Implementaciones sobre GPU}

% INTRODUCCION !!
% ACA EXPLICO CUAL ES LA BASE DE USAR OPTIMIZACION POR GPUs EN ESTE TIPO DE PROBLEMAS/ALGORITMOS DE FUTBOL ROBOT
% BLA BLA ..... DIGO QUE VOY A HACER, QUE ESPERO OBTENER, ETC......

Como se explicó previamente, una de las aproximaciones para que el procesamiento de imágenes se adapte a la realidad cambiante del juego de futbol es disminuir la latencia en todos los pasos que involucra este procesamiento.
La aceleración de esta etapa mediante el uso de GPU tiene este objetivo. 
Si la optimizacion lograda mediante el uso de funciones implementadas sobre GPU no supera el tiempo extra para transferir los datos hacia/desde la memoria GPU, entonces se reducirá el tiempo total requerido para esta etapa y las decisiones que se tomaran a continuación estarán basadas en información mas actual.

La idea de esta sección es ir planteando modificaciones individuales en el algoritmo, implementado acutalmente usando funciones sobre CPU.
El objetivo de esto es tener un conjunto de implementaciones distintas que implementen funciones independientes sobre GPU, ejecutando el resto sobre CPU.
De esta forma se puede realizar una analisis en funcion de la operacion que se esta optimizando y no del contexto en el cual ocurre.
Finalmente se plantea una version donde se implementan sobre GPU todas las funciones posibles (version mas optimizada) y es la que se usa para comparar la optimizacion lograda en el contexto de la deteccion de imagenes para futbol de robot.






% ACA SI ARRANCA LA POSTA!
% Aca explico todos los pasos de bottracker que pueden ser ejecutados sobre gpu porque estan implementados en el modulo OpenCV GPUs
\subsection{Algoritmos}

% EN ESTA SECCION DESCRIBO CUALES SON LOS 3 PASOS DEL ALGORITMO ANTERIOR QUE SE VAN A OPTIMIZAR. PONGO QUE ES LO QUE DEBERIAN HACER (QUE FUNCION APLICAN SOBRE LOS PIXELES) 
% Y DESPUES SIMPLEMENTE DIGO QUE ESTO CONCUERDA CON LA TRANSFORMACION (UNARIA O BINARIA SEGUN CORRESPONDA) QUE SE DESCRIBIO EN EL CAP. 2 (QUE SECCION??)
% ENTONCES YA ESTA IMPLEMENTADA SOBRE GPU, SIMPLEMENTE TENGO QUE REEMPLAZAR LA FUNCION QUE LLAMA ....DIGO COMO SE HACE Y LISTO


En las secciones anteriores se describio el codigo para la deteccion de imagenes en el cual se basa este trabajo. 
Este es un buen algoritmo para evaluar objetivamente las ventajas de la optimizacion mediante gpu ya que es suficientemente simple para optimizar pero a la vez tiene la complejidad que brinda un 
codigo real en el cual parte de este tiene la posibilidad de ser ?descargado?? a la gpu y otra parte del codigo debe mantenerse en la CPU(porque no tiene sentido y/o no esta implementado),
de esta forma existen distintas combinaciones de gpu/cpu que deberan ser evaluadas en cuanto a performance.


Hay 3 operaciones de este proceso que han sido implementadas en el modulo gpu de OpenCV. Las cuales se corresponden con el proceso de deteccion de blobs descrito en ref. \cite[capitulo 5.1]{Jaureguiberry}.
Repasemos en primer lugar cuales son estas 3 operaciones(visto en el capitulo de implementacion existente) y cuales son sus posiblidades de paralelizacion:
% Estas son: conversion a escala de grises, diferencia absoluta con el fondo y conversion de la diferencia a valores binarios.


% \begin{description}
%  \item [Conversion a escala de grises: ] 
\textbf{Conversion a escala de grises:} En el caso de una imagen definida en RGB, la funcion que se debe calcular es: \\[0.2em]
\indent $resultado(x,y)= 0.299  \cdot R(x,y) + 0.587  \cdot G(x,y) + 0.114  \cdot B(x,y)$\\[0.2em]
\indent Es decir, hay que realizar una ecuacion lineal sobre los valores de R, G y B de cada pixel. 
Este tipo de procesamiento concuerda con la transformacion unaria explicada en el capitulo 2.xxxx
La libreria OpenCV optimiza la conversion a escala de grises utilizando el template para transformaciones de imagenes explicado previamente.
 
Para utilizar esta aceleracion el paso de conversion se realiza ahora de la siguiente forma:

\begin{lstlisting}[columns=flexible,basicstyle=\ttfamily\small\bfseries]
    cv::gpu::cvtColor(d_frame, d_gray0, CV_BGR2GRAY);
\end{lstlisting}



 
%  \item [Diferencia absoluta: ] 
 \textbf{ Diferencia absoluta:} En este paso lo que se hace es calcular la diferencia absoluta entre el valor de cada pixel del frame(en escala de grises) y el valor del pixel correspondiente del fondo(tambien convertido a escala de grises). 
 Este proceso involucra un calculo aritmetico simple entre valores para cada pixel, y es totalmente independiente uno de otro, por lo que es totalmente paralelizable. 
 Sin embargo, el costo de este paso (que crece con el tamaño de la imagen) no es tan significativo ya que solo se debe hacer 1 calculo simple para cada posicion de la matriz.
 
 Para utilizar la funcion sobre gpu, el codigo queda:
\begin{lstlisting}[columns=flexible,basicstyle=\ttfamily\small\bfseries]
    cv::gpu::absdiff(d_gray0, d_backgroundGray, d_gray1);
\end{lstlisting}





%  \item[Conversion a valores binarios:] 
 \textbf{Conversion a valores binarios:}  Este paso también involucra una operacion simple sobre cada pixel. 
 Implica puntualmente realizar la comparacion del valor en cada pixel con un valor de threshold y asignarle 1 o 0 según sea mayor, menor o igual que este.
 La funcion que hay que calcular es: 
 \begin{displaymath}
   resultado(x,y) = \left\{
     \begin{array}{lr}
       1 &  if\ input(x,y) > threshold\\
       0 &  if\ input(x,y) \leq threshold
     \end{array}
   \right.
\end{displaymath} 

% TODO EL PROCESO DE PARALELIZACION E IMPLEMENTACION EN GPU ES IDENTICO AL DE CONVERTIR A ESCALA DE GRISES, LA DIFERENCIA ACA ES QUE LA OPERACION ES OTRA 
% SE USA EL MISMO TEMPLATE


 \begin{lstlisting}[columns=flexible,basicstyle=\ttfamily\small\bfseries]
cv::gpu::threshold(d_gray1, d_gray1, threshold, 255, CV_THRESH_BINARY);
\end{lstlisting}


%  \end{description}
 
 
 Estas 3 funcionalidades reciben por parámetros imagenenes ya alocada en la memoria de la gpu, y el resultado tambien quedará almacenado en esta memoria.
Si se quiere utilizar esta funcionalidad como parte del procesamiento de una imagen sobre cpu se debe primero enviar la imagen a la memoria de la gpu (metodo upload visto en el cap. 2)
y luego descargar los resultados nuevamente a la memoria cpu (metodo download cap. 2).
 
%  **************************
 Se debe tener en cuenta que el tiempo de procesamiento y por lo tanto el tiempo de aceleracion logrado dependen del tamaño de la imagen?? 
 ya que una imagen mayor tendra mas posibilidades de paralelizacion si es que la arquitectura lo permite.
%  PODRIA HACER UNA PRUEBA PASANDO A ESCALA DE GRISES IMAGENES DE DISTINTOS TAMAÑOS (O CALIDADES?) PARA VER COMO CAMBIA ESTO ********
 %  ****************

 Todas estas propiedades se analizarán en las proximas secciones.

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
\subsection{Sistema de pruebas}
% Aca explico el programa que se usa como prueba y el video, etc
Para realizar las pruebas se reutilizo gran parte del programa cliente descrito en \cite[capitulo 4]{Jaureguiberry}.

Una diferencia relevante es que, cuando se procesa el video de entrada, cada frame es cargado en la gpu y enviado como parametro al modulo de procesamiento. 
Una vez que se hace toda la deteccion de blobs sobre gpu se descargan los resultados a la memoria de cpu

\subsection{Resultados}
% COMO SE DESARROLLO DURANTE LOS CAPITULOS PREVIOS , EL OBJETIVO DE ESTE TRABAJO ES MEJORAR EL PROCESO DE DETECCION MEJORANDO LA LATENCIA DE ESTE.
% LOS RESULTADOS QUE NOS INTERESAN SON LOS TIEMPOS QUE DEMORA EN PROCESARSE CADA FRAME


En primer lugar se evaluaron todos los pasos iniciales del procesamiento (sobre los cuales se trabajo en la aceleracion) de forma individual.
Dado que al trabajar con GPUs se debe tener en cuenta la transferencia desde/hacia la memoria global del dispositivo, estos movimiento de datos se consideraron como un paso mas.
Las pruebas se realizaron utilizando el mismo context de ejecucion detallado en la seccion del programa cliente. Se evaluaron los valores promedio de cada operacion detallada para todos los frames del video de prueba.
De esta forma se obtuvieron los siguientes tiempos promedio:

\begin{center}
    \begin{tabular}{ c | c | c | c }
    \hline
    & GPU & CPU & Aceleracion\\ \hline
    Transferencia frame(RGB) a GPU & 707 $\mu$s &  - \\ \hline
    Conversión a escala de grises & 220 $\mu$s & 590 $\mu$s & 2.7x \\ \hline
%     Transferencia frame en escala de grises & 215 $\mu$s &  - \\ \hline
    Calculo de la dif. con la imagen del fondo & 28 $\mu$s & 197 $\mu$s & 7x\\ \hline
%     Transferencia matriz de la diferencia & 215 $\mu$s & -  \\ \hline
    Calculo de matriz binaria & 50 $\mu$s & 110 $\mu$s & 2.2x\\ \hline
    Transferencia matriz de valores binarios & 215 $\mu$s & -  \\ \hline
%     \textbf{Total} &  $\mu$s & -  \\ \hline
    \end{tabular}
\end{center}


Como se ve en la tabla, algunas de las operaciones se alcancan valores de aceleracion muy altos, lo que hace pensar que el resultado general del tiempo de ejecucion seria favorable.
Sin embargo, si hacemos la suma de estos valores (son solo valores promedio) de tiempo para el algoritmo sobre GPU y el mismo sobre CPU veremos que el total es mayor cuando intentamos derivar calculos en la GPU.

Analizando un poco mas en detalle se ve que el primer paso de conversion no provee una gran mejora en el tiempo de ejecucion y sin embargo requiere que se transfiera a la gpu la imagen inicial
que esta almacenada en un formato RGB (implica 3 colores...1 byte por cada color....bla bla). Si se hace este paso sobre la CPU , la transferencia de una imagen con la misma cantidad de pixeles pero en escala de grises
tiene un tiempo promedio de 215 $\mu$s. Si bien en este caso la modificacion no alcanza para mejorar el tiempo correspondiente a hacer todo el calculo sobre cpu, 
es util para ver que la forma de analizar la aceleracion mediante dispositivos GPU es haciendo una evaluacion de todos los tiempos asociados, tanto de computo como de transferencia.
Esto no siempre es fácil, con un caso bastante simple como este donde tenemos 7 combinaciones que parecen ser razonables. A continuación se evaluan todas ellas en el contexto del algoritmo y
se ven los tiempos resultantes de toda la ejecucion.




A continuación se muestra los resultados de la ejecucion del algoritmo global para las combinaciones mencionadas ....

\begin{center}
\makebox[\textwidth][c]{
    \begin{tabular}{ l | c }
    \hline
    Ejecucion completa en CPU & 3026.08 $\mu$s\\ \hline
    Haciendo la conversion a esc. grises en GPU & 3342.34 $\mu$s\\ \hline
    Haciendo solo el calculo de la dif. absoluta en GPU & 3233.43 $\mu$s\\ \hline
    Haciendo conversión a esc. de grises + dif. absoluta en GPU & 3332.71 $\mu$s\\ \hline
    Haciendo solo el calculo de matriz binaria en GPU &  3318.82 $\mu$s\\ \hline
    Haciendo el calculo de dif. absoluta + calc. de matriz binaria en GPU & 3276.13 $\mu$s\\ \hline
    Haciendo los 3 pasos sobre la GPU & 3315.95 $\mu$s\\ \hline
    \end{tabular}
    }
\end{center}





Analizando de forma general estos valores se puede ver que los tiempos en los que se hace el calculo de conversion a escala de grises (que requieren subir el frame en RGB a la gpu) son los que tienen mayor
diferencia con respecto al valor de CPU(1).



Hasta acá hemos visto un ejemplo de como analizar una situacion en donde tenemos computo hibrido (cpu - gpu).
Si bien el mejor analisis es haciendo las medidas correspondientes, como se menciono esto solo es posible para casos simples donde solo hay unas pocas operaciones en juego.
En la realidad es mas comun hacer un analisis global de las variables que afectan positiva y negativamente la aceleracion global mediante gpu, principalmente se deben analizar el tamaño de las imagenes 
sobre las cuales se aplican las operaciones y cuales son las operaciones que se aplican. Una imagen de mayor tamaño implica una mayor transferencia pero en muchos casos permite una mayor capacidad de paralelizacion, 
principalmente en funciones que se aplican independientemente sobre todos los pixeles. En estos caso, dada la gran cantidad de unidades de procesamiento que tienen las GPUs se podrá obtener una mayor aceleracion.

Para mostrar esto se realizaron una serie de pruebas con un conjunto de imagenes de distintas 

\begin{figure}[!ht]
\begin{center}
\makebox[\textwidth][c]{\includegraphics[keepaspectratio, width=1.1\textwidth]{img/sizeVstime.png}}
\end{center}
% \caption{Tiempo de ejecucion de la operacion Vs tamaño de la imagen}
\label{sizeevstime}
\end{figure}






\subsection{Hardware utilizado}


AMD Opteron 6320  2.8GHz 
64 Gb Memoria RAM
NVIDIA Tesla M2090 

\chapter{Conclusiones y trabajo futuro}

% BUSCAR EN ALGUN LADO (FIJARSE LAS REFERENCIAS DE Jaureguiberry) A VER CUANTO SE AVANZO EN CUANTO A LA LATENCIA DE LAS OTRAS ETAPAS DEL PROCESAMIENTO
% (POR EJ. LA ETAPA DE COMUNICACION QUE TARDABA MIL AÑOS)


En cuanto al desarrollo de software utilizando el modulo gpu.......
Es dificil sacar una conclusion   real??  acerca de la mejora en la performance que se obtiene con el modulo gpu ya que, para esto, se deberia separar el overhead relacionado con la synchronization y la transferencia de datos.
Obviamente se obtendran mejoras mas relevantes para imagenes mayores y cuando mayor cantidad de procesamiento se puede hacer teniendo los datos sobre la gpu.
% TERMINO CON:
Como principio general, como se menciona en  \cite{pulli2012real}  , los desarrolladores deberian probar diferentes combinaciones de procesamiento sobre CPU y GPU, medir los tiempos de procesamiento, y luego decidir cual es la combinacion que brinda la mejor performance





\bibliographystyle {plainnat}
\bibliography{informeEguinoa}
% \begin{thebibliography}{9}


% \bibo{lamport94}
%   Leslie Lamport,
%   \emph{\LaTeX: a document preparation system}.
%   Addison Wesley, Massachusetts,
%   2nd edition,
%   1994.

% \bibitem{Jaureguiberry2011}
% \bibitem{opencvLibrary}
  
%   \end{thebibliography}

\end{document}          